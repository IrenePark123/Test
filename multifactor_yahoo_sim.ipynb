{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrenePark123/Test/blob/main/multifactor_yahoo_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by-3sTy70QMm"
      },
      "source": [
        "# Multi‑Factor (Cholesky) Monte Carlo using Yahoo Finance\n",
        "\n",
        "This notebook implements a **multi‑factor, Cholesky‑based one‑day Monte Carlo** simulation using **Yahoo Finance** data (via `yfinance`). It is structured into clear sections so you can run top‑to‑bottom or adapt pieces (e.g., add EWMA, 2‑day MPOR, AM/PM split, skew‑t, etc.).\n",
        "\n",
        "**What you'll get:**\n",
        "- Data pull and aligned daily log‑returns for **drivers** and **factors**\n",
        "- Correlation calibration and **extended Cholesky** block construction (Ψ, Φ, Λ)\n",
        "- Student‑t Monte Carlo for **1‑day horizon**\n",
        "- Scenario‑level repricing and percentile summaries\n",
        "- Diagnostics for correlation recovery and λ‑sanity\n",
        "\n",
        "> Tip: Adjust the ticker lists and horizon in the **Configuration** cell.\n"
      ],
      "id": "by-3sTy70QMm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGsyWASt0QMq"
      },
      "source": [
        "## 0) Environment & Dependencies\n",
        "\n",
        "If you don't have `yfinance` installed in this environment, run the next cell. (It's safe to re‑run.)"
      ],
      "id": "NGsyWASt0QMq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asG8d8Sr0QMr"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --upgrade yfinance pandas numpy matplotlib"
      ],
      "id": "asG8d8Sr0QMr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-GY_2GU0QMs"
      },
      "source": [
        "## 1) Imports & Reproducibility"
      ],
      "id": "C-GY_2GU0QMs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryVwsxpq0QMt"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from numpy.linalg import cholesky, LinAlgError\n",
        "\n",
        "# Reproducibility\n",
        "rng = np.random.default_rng(42)"
      ],
      "id": "ryVwsxpq0QMt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mitiFaE90QMt"
      },
      "source": [
        "## 2) Configuration (edit me)\n",
        "\n",
        "- **Drivers**: broad market/sector/macro series\n",
        "- **Factors**: single names or narrower ETFs you want to simulate\n",
        "- **Horizon**: one trading day by default\n",
        "- **Scenarios**: Monte Carlo paths"
      ],
      "id": "mitiFaE90QMt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8HEhcxn0QMt"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Date range for historical calibration\n",
        "start = \"2016-01-01\"\n",
        "end   = None  # None -> up to today\n",
        "\n",
        "# Example drivers (adjust to your preference)\n",
        "driver_tickers = [\n",
        "    \"SPY\",         # US large-cap proxy\n",
        "    \"IWM\",         # US small-cap proxy\n",
        "    \"EEM\",         # EM equities\n",
        "    \"XLK\", \"XLF\",  # Tech, Financials\n",
        "    \"IEF\", \"HYG\",  # 7-10Y UST, High Yield\n",
        "    \"GLD\", \"SLV\",  # Gold, Silver\n",
        "    \"USO\", \"UNG\"   # Oil, NatGas\n",
        "]\n",
        "\n",
        "# Example risk factors (single names + thematics)\n",
        "factor_tickers = [\n",
        "    \"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\",\n",
        "    \"TSLA\", \"META\", \"JPM\", \"XOM\",\n",
        "    \"QQQ\", \"TLT\"\n",
        "]\n",
        "\n",
        "# Simulation settings\n",
        "nu_driver   = 5      # Student-t df for drivers\n",
        "nu_factor   = 5      # Student-t df for idiosyncratic components\n",
        "mpor_days   = 1      # Horizon in trading days (Δt); currently 1-day\n",
        "n_scenarios = 10000  # Monte Carlo scenario count"
      ],
      "id": "R8HEhcxn0QMt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv3tyt2F0QMu"
      },
      "source": [
        "## 3) Data Download & Aligned Log‑Returns\n",
        "\n",
        "Pull **Adj Close** prices, convert to daily **log returns**, and align calendars across drivers & factors. We also filter out columns with too few observations to ensure robust statistics."
      ],
      "id": "Cv3tyt2F0QMu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "cOBnYRRU0QMu",
        "outputId": "dfb8f234-69e6-41e3-c238-dce547b73d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "After filtering for sufficient observations, no driver or factor columns remain. Try reducing 'min_obs' or choosing tickers with longer history.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2479644587.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mret_drivers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mret_factors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     raise ValueError(\"After filtering for sufficient observations, no driver or factor columns remain. \"\n\u001b[0m\u001b[1;32m     26\u001b[0m                      \"Try reducing 'min_obs' or choosing tickers with longer history.\")\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: After filtering for sufficient observations, no driver or factor columns remain. Try reducing 'min_obs' or choosing tickers with longer history."
          ]
        }
      ],
      "source": [
        "def download_prices(tickers, start=None, end=None):\n",
        "    df = yf.download(tickers, start=start, end=end, auto_adjust=True, progress=False)[\"Close\"]\n",
        "    if isinstance(df, pd.Series):\n",
        "        df = df.to_frame()\n",
        "    return df.dropna(how=\"all\")\n",
        "\n",
        "def log_returns(prices: pd.DataFrame) -> pd.DataFrame:\n",
        "    return np.log(prices).diff().dropna(how=\"all\")\n",
        "\n",
        "# Download\n",
        "px_drivers = download_prices(driver_tickers, start, end)\n",
        "px_factors = download_prices(factor_tickers, start, end)\n",
        "\n",
        "# Returns and calendar alignment\n",
        "ret_drivers = log_returns(px_drivers)\n",
        "ret_factors = log_returns(px_factors)\n",
        "ret_drivers, ret_factors = ret_drivers.align(ret_factors, join=\"inner\")\n",
        "\n",
        "# Keep only columns with enough data\n",
        "min_obs = 252  # ~1 year of trading days\n",
        "ret_drivers = ret_drivers.dropna(axis=1, thresh=min_obs)\n",
        "ret_factors = ret_factors.dropna(axis=1, thresh=min_obs)\n",
        "\n",
        "if ret_drivers.shape[1] == 0 or ret_factors.shape[1] == 0:\n",
        "    raise ValueError(\"After filtering for sufficient observations, no driver or factor columns remain. \"\n",
        "                     \"Try reducing 'min_obs' or choosing tickers with longer history.\")\n",
        "\n",
        "driver_cols = ret_drivers.columns.tolist()\n",
        "factor_cols = ret_factors.columns.tolist()\n",
        "\n",
        "print(f\"Drivers ({len(driver_cols)}): {driver_cols}\")\n",
        "print(f\"Factors ({len(factor_cols)}): {factor_cols}\")"
      ],
      "id": "cOBnYRRU0QMu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NDLVM6Y0QMu"
      },
      "source": [
        "## 4) Utilities\n",
        "\n",
        "- **Nearest correlation (Higham)**: projects a symmetric matrix to the nearest correlation (PSD, unit diagonal).\n",
        "- **Cross‑correlation**: full Pearson correlation between columns of X (rows) and Y (cols).\n",
        "- **Vol estimator**: sample daily sigma (swap for EWMA if desired)."
      ],
      "id": "-NDLVM6Y0QMu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfjQvK-y0QMv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def nearest_correlation_higham(A, tol=1e-12, max_iter=100):\n",
        "    \"\"\"Higham (2002) nearest correlation matrix projection (PSD + unit diagonal).\"\"\"\n",
        "    A = (A + A.T) / 2\n",
        "    n = A.shape[0]\n",
        "    X = A.copy()\n",
        "    Y = A.copy()\n",
        "    deltaS = np.zeros_like(A)\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        R = X - deltaS\n",
        "        eigvals, eigvecs = np.linalg.eigh(R)\n",
        "        eigvals_clipped = np.maximum(eigvals, 0.0)\n",
        "        X = (eigvecs * eigvals_clipped) @ eigvecs.T\n",
        "        X[np.diag_indices(n)] = 1.0\n",
        "        deltaS = X - R\n",
        "        if np.linalg.norm(X - Y, ord=\"fro\") < tol:\n",
        "            break\n",
        "        Y = X.copy()\n",
        "    return X\n",
        "\n",
        "def cross_corr(X: pd.DataFrame, Y: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"Full Pearson correlation between columns of X (rows) and Y (cols).\"\"\"\n",
        "    # Standardize\n",
        "    Xc = (X - X.mean()) / X.std(ddof=1)\n",
        "    Yc = (Y - Y.mean()) / Y.std(ddof=1)\n",
        "    n = len(Xc)\n",
        "    return (Xc.T @ Yc / (n - 1)).T  # shape: (X_cols, Y_cols)\n",
        "\n",
        "def sample_vols(returns: pd.DataFrame, window=252) -> pd.Series:\n",
        "    \"\"\"Daily sigma via sample stdev over a trailing window.\"\"\"\n",
        "    daily_sigma = returns.rolling(window).std().dropna().iloc[-1]\n",
        "    return daily_sigma"
      ],
      "id": "cfjQvK-y0QMv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfe9jg-X0QMv"
      },
      "source": [
        "## 5) Calibration: Ψ (driver‑driver), Φ (driver‑factor), and Λ (idiosyncratic)\n",
        "\n",
        "- **Ψ** from Cholesky of the driver‑driver correlation (PSD enforced via Higham if needed)\n",
        "- **Φ = C<sub>XY</sub> (Ψ<sup>−1</sup>)<sup>T</sup>**\n",
        "- **λ<sub>j</sub> = √(1 − ‖Φ<sub>j·</sub>‖²)** as the uncorrelated idiosyncratic part per factor"
      ],
      "id": "nfe9jg-X0QMv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pThc4SQC0QMv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def calibrate_correlations(RY: pd.DataFrame, RX: pd.DataFrame):\n",
        "    K = RY.shape[1]\n",
        "    N = RX.shape[1]\n",
        "\n",
        "    # Correlations\n",
        "    C_YY = RY.corr().values              # KxK\n",
        "    C_XY = cross_corr(RX, RY)            # NxK\n",
        "    C_XX = RX.corr().values              # NxN (diagnostics only)\n",
        "\n",
        "    # Ensure PSD for driver-driver; get lower-triangular Psi\n",
        "    try:\n",
        "        Psi = cholesky(C_YY).T  # lower-triangular\n",
        "    except LinAlgError:\n",
        "        C_YY_psd = nearest_correlation_higham(C_YY)\n",
        "        Psi = cholesky(C_YY_psd).T\n",
        "\n",
        "    # Phi = C_XY * (Psi^{-1})^T\n",
        "    Psi_inv_T = np.linalg.inv(Psi).T\n",
        "    Phi = C_XY @ Psi_inv_T  # NxK\n",
        "\n",
        "    # Lambda diagonal from unit-norm constraint\n",
        "    row_norm_sq = np.sum(Phi**2, axis=1)\n",
        "    row_norm_sq = np.clip(row_norm_sq, 0.0, 1.0)\n",
        "    Lambda_diag = np.sqrt(1.0 - row_norm_sq)\n",
        "    Lambda = np.diag(Lambda_diag)\n",
        "\n",
        "    blocks = {\"C_YY\": C_YY, \"C_XY\": C_XY, \"C_XX\": C_XX}\n",
        "    return Psi, Phi, Lambda, blocks\n",
        "\n",
        "# Daily sigmas (can replace with EWMA if desired)\n",
        "sigmaY_daily = sample_vols(ret_drivers)\n",
        "sigmaX_daily = sample_vols(ret_factors)\n",
        "\n",
        "Psi, Phi, Lambda, corr_blocks = calibrate_correlations(ret_drivers, ret_factors)\n",
        "\n",
        "print(\"Psi shape:\", Psi.shape)\n",
        "print(\"Phi shape:\", Phi.shape)\n",
        "print(\"Lambda diag (min, max):\", float(np.min(np.diag(Lambda))), float(np.max(np.diag(Lambda))))"
      ],
      "id": "pThc4SQC0QMv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INBreUnX0QMv"
      },
      "source": [
        "## 6) Simulation (1‑day)\n",
        "\n",
        "We simulate one trading day using:\n",
        "\\[ r = \\Sigma \\cdot L \\cdot z \\cdot \\sqrt{\\Delta t} \\]\n",
        "with extended Cholesky\n",
        "\\( L = \\begin{bmatrix}\\Psi & 0 \\\\ \\Phi & \\Lambda \\end{bmatrix} \\),\n",
        "daily sigmas on the diagonal of \\(\\Sigma\\), and **Student‑t** noise for drivers and factors."
      ],
      "id": "INBreUnX0QMv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mAdUktK0QMw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def simulate_one_day(Psi, Phi, Lambda,\n",
        "                     sigmaY: pd.Series,\n",
        "                     sigmaX: pd.Series,\n",
        "                     n_scenarios=10000,\n",
        "                     nu_driver=5, nu_factor=5,\n",
        "                     annual_trading_days=252):\n",
        "    K = len(sigmaY)\n",
        "    N = len(sigmaX)\n",
        "\n",
        "    # L block\n",
        "    top = np.hstack([Psi, np.zeros((K, N))])\n",
        "    bot = np.hstack([Phi, Lambda])\n",
        "    L = np.vstack([top, bot])  # (K+N) x (K+N)\n",
        "\n",
        "    # Sigma vector (daily)\n",
        "    sigma_vec = np.concatenate([sigmaY.values, sigmaX.values])\n",
        "\n",
        "    # Student-t innovations\n",
        "    ZY = rng.standard_t(df=nu_driver, size=(n_scenarios, K))\n",
        "    ZX = rng.standard_t(df=nu_factor, size=(n_scenarios, N))\n",
        "    Z  = np.concatenate([ZY, ZX], axis=1)\n",
        "\n",
        "    dt_sqrt = np.sqrt(1.0 / annual_trading_days)\n",
        "\n",
        "    shocks = Z @ L.T\n",
        "    scaled = shocks * (sigma_vec * dt_sqrt)  # broadcast\n",
        "\n",
        "    rY = scaled[:, :K]\n",
        "    rX = scaled[:, K:]\n",
        "    return rY, rX\n",
        "\n",
        "rY_sim, rX_sim = simulate_one_day(\n",
        "    Psi, Phi, Lambda,\n",
        "    sigmaY_daily[driver_cols],\n",
        "    sigmaX_daily[factor_cols],\n",
        "    n_scenarios=n_scenarios,\n",
        "    nu_driver=nu_driver,\n",
        "    nu_factor=nu_factor\n",
        ")\n",
        "\n",
        "print(\"Simulated rY shape:\", rY_sim.shape)\n",
        "print(\"Simulated rX shape:\", rX_sim.shape)"
      ],
      "id": "5mAdUktK0QMw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD9pm6Ch0QMw"
      },
      "source": [
        "## 7) Re‑price Levels & Summaries\n",
        "\n",
        "Using last observed prices \\(P_t\\), one‑day levels are \\(P_{t+1}^{(i)} = P_t \\cdot e^{r^{(i)}}\\). We show percentile summaries for both drivers and factors."
      ],
      "id": "OD9pm6Ch0QMw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6gipTMR0QMw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "last_drivers = px_drivers[driver_cols].iloc[-1].values\n",
        "last_factors = px_factors[factor_cols].iloc[-1].values\n",
        "\n",
        "pxY_scenarios = last_drivers * np.exp(rY_sim)\n",
        "pxX_scenarios = last_factors * np.exp(rX_sim)\n",
        "\n",
        "Y_summary = pd.DataFrame(pxY_scenarios, columns=driver_cols).describe(percentiles=[0.01,0.05,0.5,0.95,0.99]).T\n",
        "X_summary = pd.DataFrame(pxX_scenarios, columns=factor_cols).describe(percentiles=[0.01,0.05,0.5,0.95,0.99]).T\n",
        "\n",
        "print(\"Driver price summary (selected rows):\")\n",
        "display(Y_summary[['mean','std','1%','5%','50%','95%','99%']].round(4))\n",
        "\n",
        "print(\"\\nFactor price summary (selected rows):\")\n",
        "display(X_summary[['mean','std','1%','5%','50%','95%','99%']].round(4))"
      ],
      "id": "j6gipTMR0QMw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WApynBN50QMw"
      },
      "source": [
        "## 8) Diagnostics\n",
        "\n",
        "- **Correlation recovery**: compare simulated against historical targets.\n",
        "- **λ sanity**: ensure all \\(\\lambda_j \\in [0,1]\\)."
      ],
      "id": "WApynBN50QMw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK25rTcM0QMx"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Targets\n",
        "C_YY_target = corr_blocks[\"C_YY\"]\n",
        "C_XY_target = corr_blocks[\"C_XY\"]\n",
        "\n",
        "# Simulated\n",
        "sim_Y = pd.DataFrame(rY_sim, columns=driver_cols)\n",
        "sim_X = pd.DataFrame(rX_sim, columns=factor_cols)\n",
        "\n",
        "C_YY_sim = sim_Y.corr().values\n",
        "# cross corr: rows=factors, cols=drivers\n",
        "def _cross_corr_np(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
        "    Xc = (X - X.mean(axis=0)) / X.std(axis=0, ddof=1)\n",
        "    Yc = (Y - Y.mean(axis=0)) / Y.std(axis=0, ddof=1)\n",
        "    return (Xc.T @ Yc / (Xc.shape[0] - 1)).T\n",
        "\n",
        "C_XY_sim = _cross_corr_np(sim_X.values, sim_Y.values)\n",
        "\n",
        "mae_driver_driver = float(np.mean(np.abs(C_YY_sim - C_YY_target)))\n",
        "mae_driver_factor = float(np.mean(np.abs(C_XY_sim - C_XY_target)))\n",
        "\n",
        "lam_diag = np.diag(Lambda)\n",
        "lam_min, lam_max = float(lam_diag.min()), float(lam_diag.max())\n",
        "\n",
        "print(f\"MAE corr — driver/driver: {mae_driver_driver:.3f}  |  driver/factor: {mae_driver_factor:.3f}\")\n",
        "print(f\"Lambda diag in [min, max] = [{lam_min:.3f}, {lam_max:.3f}]\")"
      ],
      "id": "PK25rTcM0QMx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xjtF2-O0QMx"
      },
      "source": [
        "## 9) Easy Extensions (placeholders)\n",
        "\n",
        "- **EWMA volatility**: replace `sample_vols` with an EWMA estimator for more reactive sigmas.\n",
        "- **2‑day MPOR**: draw a fresh \\(z\\) for day‑2 and add the day‑1/day‑2 returns.\n",
        "- **AM/PM split**: simulate with two sub‑intervals per day and aggregate.\n",
        "- **Skew‑t**: swap the Student‑t sampler with a skewed‑t generator (same block structure).\n",
        "\n",
        "> If you want a version pre‑wired for EWMA or 2‑day MPOR, tell me your exact tickers and horizon and I’ll generate it.\n"
      ],
      "id": "-xjtF2-O0QMx"
    }
  ]
}